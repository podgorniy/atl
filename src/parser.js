// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
export const parser = LRParser.deserialize({
  version: 14,
  states: "nOQOPOOOOOO'#C^'#C^OOOO'#Ca'#CaQQOPOOOOOO-E6_-E6_",
  stateData: "Y~ORPOSPO~O",
  goto: "aUPPVPPZTQORQRORSR",
  nodeNames: "âš  TemplateString Expression VariableUse Text",
  maxTerm: 6,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "%R~RUO#oe#o#p!P#p#qe#r;'Se;'S;=`y<%lOe~jTS~O#oe#p#qe#r;'Se;'S;=`y<%lOe~|P;=`<%le~!S_X^!Ppq!P}!O#R!Q![#R!c!}#R#R#S#R#T#o#R#y#z!P$f$g!P#BY#BZ!P$IS$I_!P$I|$JO!P$JT$JU!P$KV$KW!P&FU&FV!P~#U`X^$Wpq$W}!O#R!Q![#R!c!}#R#R#S#R#T#o#R#q#r$|#y#z$W$f$g$W#BY#BZ$W$IS$I_$W$I|$JO$W$JT$JU$W$KV$KW$W&FU&FV$W~$ZZX^$Wpq$W#q#r$|#y#z$W$f$g$W#BY#BZ$W$IS$I_$W$I|$JO$W$JT$JU$W$KV$KW$W&FU&FV$W~%ROR~",
  tokenizers: [0],
  topRules: {"TemplateString":[0,1]},
  tokenPrec: 0
})
